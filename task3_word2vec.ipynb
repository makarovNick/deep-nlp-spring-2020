{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1.3: Naive word2vec (40 points)\n",
    "\n",
    "This task can be formulated very simply. Follow this [paper](https://arxiv.org/pdf/1411.2738.pdf) and implement word2vec like a two-layer neural network with matrices $W$ and $W'$. One matrix projects words to low-dimensional 'hidden' space and the other - back to high-dimensional vocabulary space.\n",
    "\n",
    "![word2vec](https://i.stack.imgur.com/6eVXZ.jpg)\n",
    "\n",
    "You can use TensorFlow/PyTorch and code from your previous task.\n",
    "\n",
    "## Results of this task: (30 points)\n",
    " * trained word vectors (mention somewhere, how long it took to train)\n",
    " * plotted loss (so we can see that it has converged)\n",
    " * function to map token to corresponding word vector\n",
    " * beautiful visualizations (PCE, T-SNE), you can use TensorBoard and play with your vectors in 3D (don't forget to add screenshots to the task)\n",
    "\n",
    "## Extra questions: (10 points)\n",
    " * Intrinsic evaluation: you can find datasets [here](http://download.tensorflow.org/data/questions-words.txt)\n",
    " * Extrinsic evaluation: you can use [these](https://medium.com/@dataturks/rare-text-classification-open-datasets-9d340c8c508e)\n",
    "\n",
    "Also, you can find any other datasets for quantitative evaluation.\n",
    "\n",
    "Again. It is **highly recommended** to read this [paper](https://arxiv.org/pdf/1411.2738.pdf)\n",
    "\n",
    "Example of visualization in tensorboard:\n",
    "https://projector.tensorflow.org\n",
    "\n",
    "Example of 2D visualisation:\n",
    "\n",
    "![2dword2vec](https://www.tensorflow.org/images/tsne.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from batcher import Batcher\n",
    "\n",
    "SEED = 42\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 \n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print('using device:', device)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.linear1 = nn.Linear(vocab_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./text8') as file:\n",
    "        data = file.read().split()\n",
    "\n",
    "vocab_size = 15000\n",
    "batch_size = 1000\n",
    "window_size = 5\n",
    "train_data = data[:30000]\n",
    "\n",
    "batcher = Batcher(train_data, window_size, batch_size, vocab_size)\n",
    "data_loader = iter(batcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 30\n",
    "\n",
    "model = CBOW(vocab_size=vocab_size, hidden_size=hidden_size)\n",
    "model = model.to(device=device)\n",
    "\n",
    "loss = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OHE(data, vocab_size, batch_size=2):  \n",
    "    if batch_size != 1:\n",
    "        ohe = torch.zeros((len(data), vocab_size))\n",
    "        for index, words in enumerate(batch):\n",
    "            for word in words:\n",
    "                ohe[index][word] = ohe[index, word] + 1\n",
    "    else:\n",
    "        ohe = torch.zeros(vocab_size)\n",
    "        for word in data:\n",
    "            ohe[word] = 1\n",
    "            \n",
    "    return ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30000\n",
    "\n",
    "print_every = len(train_data) // batch_size\n",
    "losses = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    batch, labels = next(data_loader)\n",
    "    X = torch.tensor(OHE(batch, vocab_size) / window_size, device=device, dtype = dtype)\n",
    "    y = torch.tensor(labels, device=device, dtype=torch.long)\n",
    "\n",
    "    model.train() \n",
    "    preds = model(X).to(device=device, dtype=dtype)\n",
    "    los = loss(preds, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    los.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(los.item())\n",
    "    if epoch % print_every == 0:\n",
    "        print('Iteration %d, loss = %.4lg' % (epoch, sum(losses[-print_every:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "<img src = \"./loss.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBOW(vocab_size=vocab_size, hidden_size=hidden_size)\n",
    "model.load_state_dict(torch.load(\"./model\", map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = lambda x: model.linear1(OHE([batcher.w2i[x]], vocab_size, batch_size=1)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(word1, word2):\n",
    "    return np.dot(word1, word2) / (np.linalg.norm(word1)* np.linalg.norm(word2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(word):\n",
    "    d = {}\n",
    "    for w in batcher.data:\n",
    "        d.update({cos_similarity(word2vec(batcher.i2w[w]), word2vec(word)) : batcher.i2w[w]})\n",
    "    return [d[k] for k in sorted(d, reverse = True)[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['camera',\n",
       " 'sets',\n",
       " 'determines',\n",
       " 'alanine',\n",
       " 'archaeological',\n",
       " 'islands',\n",
       " 'user',\n",
       " 'biochemistry',\n",
       " 'cameras',\n",
       " 'mode']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "plot_only = 200\n",
    "final_embeddings = []\n",
    "final_embeddings = [batch.i2w[i] for i in range(plot_only)]\n",
    "low_dim_embs = tsne.fit_transform(np.array(final_embeddings))\n",
    "labels = [idx2word[i] for i in range(plot_only)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (new)",
   "language": "python",
   "name": "new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
